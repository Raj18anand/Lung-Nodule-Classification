{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd635852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "def readCsv(csvfname):\n",
    "    # read csv to list of lists\n",
    "    with open(csvfname, 'r') as csvf:\n",
    "        reader = csv.reader(csvf)\n",
    "        csvlines = list(reader)\n",
    "    return csvlines\n",
    "\n",
    "def writeCsv(csfname,rows):\n",
    "    # write csv from list of lists\n",
    "    with open(csfname, 'w', newline='') as csvf:\n",
    "        filewriter = csv.writer(csvf)\n",
    "        filewriter.writerows(rows)\n",
    "        \n",
    "def readMhd(filename):\n",
    "    # read mhd/raw image\n",
    "    itkimage = sitk.ReadImage(filename)\n",
    "    scan = sitk.GetArrayFromImage(itkimage) #3D image\n",
    "    spacing = itkimage.GetSpacing() #voxelsize\n",
    "    origin = itkimage.GetOrigin() #world coordinates of origin\n",
    "    transfmat = itkimage.GetDirection() #3D rotation matrix\n",
    "    return scan,spacing,origin,transfmat\n",
    "\n",
    "def writeMhd(filename,scan,spacing,origin,transfmat):\n",
    "    # write mhd/raw image\n",
    "    itkim = sitk.GetImageFromArray(scan, isVector=False) #3D image\n",
    "    itkim.SetSpacing(spacing) #voxelsize\n",
    "    itkim.SetOrigin(origin) #world coordinates of origin\n",
    "    itkim.SetDirection(transfmat) #3D rotation matrix\n",
    "    sitk.WriteImage(itkim, filename, False)    \n",
    "\n",
    "def getImgWorldTransfMats(spacing,transfmat):\n",
    "    # calc image to world to image transformation matrixes\n",
    "    transfmat = np.array([transfmat[0:3],transfmat[3:6],transfmat[6:9]])\n",
    "    for d in range(3):\n",
    "        transfmat[0:3,d] = transfmat[0:3,d]*spacing[d]\n",
    "    transfmat_toworld = transfmat #image to world coordinates conversion matrix\n",
    "    transfmat_toimg = np.linalg.inv(transfmat) #world to image coordinates conversion matrix\n",
    "    \n",
    "    return transfmat_toimg,transfmat_toworld\n",
    "\n",
    "def convertToImgCoord(xyz,origin,transfmat_toimg):\n",
    "    # convert world to image coordinates\n",
    "    xyz = xyz - origin\n",
    "    xyz = np.round(np.matmul(transfmat_toimg,xyz))    \n",
    "    return xyz\n",
    "    \n",
    "def convertToWorldCoord(xyz,origin,transfmat_toworld):\n",
    "    # convert image to world coordinates\n",
    "    xyz = np.matmul(transfmat_toworld,xyz)\n",
    "    xyz = xyz + origin\n",
    "    return xyz\n",
    "\n",
    "def extractCube(scan,spacing,xyz,cube_size=64,cube_size_mm=51):\n",
    "    # Extract cube of cube_size^3 voxels and world dimensions of cube_size_mm^3 mm from scan at image coordinates xyz\n",
    "    xyz = np.array([xyz[i] for i in [2,1,0]],np.int)\n",
    "    spacing = np.array([spacing[i] for i in [2,1,0]])\n",
    "    scan_halfcube_size = np.array(cube_size_mm/spacing/2,np.int)\n",
    "    if np.any(xyz<scan_halfcube_size) or np.any(xyz+scan_halfcube_size>scan.shape): # check if padding is necessary\n",
    "        maxsize = max(scan_halfcube_size)\n",
    "        scan = np.pad(scan,((maxsize,maxsize,)),'constant',constant_values=0)\n",
    "        xyz = xyz+maxsize\n",
    "    \n",
    "    scancube = scan[xyz[0]-scan_halfcube_size[0]:xyz[0]+scan_halfcube_size[0], # extract cube from scan at xyz\n",
    "                    xyz[1]-scan_halfcube_size[1]:xyz[1]+scan_halfcube_size[1],\n",
    "                    xyz[2]-scan_halfcube_size[2]:xyz[2]+scan_halfcube_size[2]]\n",
    "\n",
    "    sh = scancube.shape\n",
    "    scancube = zoom(scancube,(cube_size/sh[0],cube_size/sh[1],cube_size/sh[2]),order=2) #resample for cube_size\n",
    "    \n",
    "    return scancube\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b35db755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import pandas\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import random\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color\n",
    "from numpy import newaxis\n",
    "import csv\n",
    "import sys\n",
    "from scipy.ndimage import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4a9a226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Model\n",
    "from keras.layers import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "adam = Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83e14502",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-0c370ad15cb4>:62: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  xyz = np.array([xyz[i] for i in [2,1,0]],np.int)\n",
      "<ipython-input-1-0c370ad15cb4>:64: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  scan_halfcube_size = np.array(cube_size_mm/spacing/2,np.int)\n"
     ]
    }
   ],
   "source": [
    "X= []\n",
    "y= []\n",
    "\n",
    "dataset = \"basedata/\"\n",
    "file_list = glob.glob(dataset + '*.mhd')\n",
    "\n",
    "\n",
    "for file_path in file_list: \n",
    "    base = os.path.basename(file_path)\n",
    "    lnd = int(os.path.splitext(base)[0][5:])\n",
    "    [scan,spacing,origin,transfmat] =  readMhd(file_path)\n",
    "    \n",
    "    csvlines = readCsv(\"trainset_csv/trainNodules_gt.csv\")\n",
    "    header = csvlines[0]\n",
    "    nodules = csvlines[1:]\n",
    "    itr=0\n",
    "    flag=0\n",
    "    max_agreement=0\n",
    "    for n in nodules:\n",
    "        if int(n[header.index('LNDbID')])==lnd:\n",
    "            if(itr==0 or int(n[header.index('AgrLevel')])>max_agreement):\n",
    "                ctr = np.array([float(n[header.index('x')]), float(n[header.index('y')]), float(n[header.index('z')])])\n",
    "                y.append(int(n[header.index('Nodule')]))\n",
    "#                 print(lnd,int(n[header.index('Nodule')]))\n",
    "                max_agreement=int(n[header.index('AgrLevel')])\n",
    "                flag=1\n",
    "                break\n",
    "    \n",
    "#   Convert coordinates to image\n",
    "    if(flag==1):\n",
    "        transfmat_toimg,transfmat_toworld = getImgWorldTransfMats(spacing,transfmat)\n",
    "        ctr = convertToImgCoord(ctr,origin,transfmat_toimg)\n",
    "        scan_cube = extractCube(scan,spacing,ctr)\n",
    "        X.append(scan_cube[int(scan_cube.shape[0]/2),:,:])\n",
    "#         plt.imshow(scan_cube[int(scan_cube.shape[0]/2),:,:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38cc2a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features, X shape:  (229, 64, 64)\n",
      "Target, y shape:  (229,)\n",
      "Data shape:  (229, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Get images as a 4,096 feature set\n",
    "SAMPLE_SIZE = len(y)\n",
    "data = np.array(X).flatten().reshape(SAMPLE_SIZE, 64*64) # pixel-features\n",
    "\n",
    "# Turn X and y into numpy arrays\n",
    "X = np.array(X).reshape(-1, 64, 64) # images\n",
    "y = np.array(y) # target\n",
    "\n",
    "print(\"Features, X shape: \", X.shape)\n",
    "print(\"Target, y shape: \", y.shape)\n",
    "print(\"Data shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88090136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#Saves us from having to regenerate our data by saving our data\n",
    "pickle_out = open(\"X.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"data.pickle\", \"wb\")\n",
    "pickle.dump(data, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
